{
    "id": null,
    "metadata": {
        "source": "../datasets/2023.acl-long.732.pdf",
        "detection_class_prob": 0.9454086422920227,
        "coordinates": {
            "points": [
                [
                    192.73915100097656,
                    1054.38037109375
                ],
                [
                    192.73915100097656,
                    1681.4129638671875
                ],
                [
                    818.6885986328125,
                    1681.4129638671875
                ],
                [
                    818.6885986328125,
                    1054.38037109375
                ]
            ],
            "system": "PixelSpace",
            "layout_width": 1654,
            "layout_height": 2339
        },
        "last_modified": "2025-07-10T10:14:34",
        "filetype": "application/pdf",
        "languages": [
            "eng"
        ],
        "page_number": 8,
        "parent_id": "0e7d66f88dacd8be7f846ecf4d89c471",
        "file_directory": "../datasets",
        "filename": "2023.acl-long.732.pdf",
        "category": "NarrativeText",
        "element_id": "0f49c8662abfefe15bc19a45f59d8c82"
    },
    "page_content": "Given the importance of interpretability in machine learning, we investigate the necessity of local con- text realised by cross-modal LCA and global se- mantic context captured by semantic refinement module. We explore the distribution of distances between the target utterance and its second (2nd) highest attended utterance according to our atten- tion scores for all the utterances correctly classified. First, most of the correctly classified utterances depend on their local context when a significant portion is also present for the distant context. Be- sides, the dependence on distant context shows more significance for the 2nd highest attention, which highlight the importance of the long-term emotional dependency. Meanwhile, the contextual dependence exists both towards the past and the future utterances.",
    "type": "Document"
}