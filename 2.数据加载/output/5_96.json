{
    "id": null,
    "metadata": {
        "source": "../datasets/2023.acl-long.732.pdf",
        "detection_class_prob": 0.9444452524185181,
        "coordinates": {
            "points": [
                [
                    846.5977783203125,
                    694.66943359375
                ],
                [
                    846.5977783203125,
                    1250.6922607421875
                ],
                [
                    1468.0966796875,
                    1250.6922607421875
                ],
                [
                    1468.0966796875,
                    694.66943359375
                ]
            ],
            "system": "PixelSpace",
            "layout_width": 1654,
            "layout_height": 2339
        },
        "last_modified": "2025-07-10T10:14:34",
        "filetype": "application/pdf",
        "languages": [
            "eng"
        ],
        "page_number": 5,
        "parent_id": "fcd22fcfdd8e1c7239f9bbbdf88b319a",
        "file_directory": "../datasets",
        "filename": "2023.acl-long.732.pdf",
        "category": "NarrativeText",
        "element_id": "2b907b884547ec18e0aadfd2b8a1605a"
    },
    "page_content": "We performed all experiments on the Pytorch deep learning framework with the Intel Core i7-12700H and the NVIDIA RTX3060 GPU. The software environment includes Python 3.9, Pytorch 1.12.1, and CUDA 11.3. Adam optimizer with an ini- tial learning rate of 0.0001 is used to optimize the parameters in the proposed CMCF-SRNet and a dropout rate of 0.5 is adopted. The head number is set to 4 for cross-modal transformer and 2 for graph-transformer. Besides, audio features (size 100) are extracted using OpenSmile (Eyben et al., 2010) and text features (size 768) are extracted us- ing sBERT (Reimers and Gurevych, 2019). We re-run on each dataset five times and calculate the mean and standard deviations.",
    "type": "Document"
}